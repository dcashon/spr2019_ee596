{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T01:19:12.823621Z",
     "start_time": "2019-04-27T01:19:10.565767Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import timeit\n",
    "import load_cifar\n",
    "import time\n",
    "\n",
    "# D. Cashon\n",
    "# 2019 04 26\n",
    "# implementing tensorflow dense NN for \n",
    "# CIFAR 10 classification\n",
    "# docs say to use keras API but will use tf.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T01:19:13.002821Z",
     "start_time": "2019-04-27T01:19:12.823621Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# also get validation and test\n",
    "val_data, val_labels = load_cifar.load_preprocessed_validation_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Hyper-perparmeter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T01:19:13.022957Z",
     "start_time": "2019-04-27T01:19:13.005833Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.01\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T01:19:13.082832Z",
     "start_time": "2019-04-27T01:19:13.026969Z"
    }
   },
   "outputs": [],
   "source": [
    "# for feeding the minibatches\n",
    "x_data = tf.placeholder(tf.float32, shape=[None, 3072])\n",
    "y_labels = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Neural Network Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T01:19:13.262975Z",
     "start_time": "2019-04-27T01:19:13.082832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-a0cd0dc40be9>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/lusers/dcashon/.conda/envs/neural_nets/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# tried stuff, this seems to work OK\n",
    "lay1 = tf.layers.dense(x_data, 128, activation=tf.nn.relu)\n",
    "lay2 = tf.layers.dense(lay1, 256, activation=tf.nn.relu)\n",
    "lay3 = tf.layers.dense(lay2, 512, activation=tf.nn.relu)\n",
    "# output layer\n",
    "output = tf.layers.dense(lay2, 10, activation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define cost and optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T01:19:13.738022Z",
     "start_time": "2019-04-27T01:19:13.266986Z"
    }
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_labels, logits=output))\n",
    "opt = tf.train.AdamOptimizer()\n",
    "to_minimize = opt.minimize(cost)\n",
    "\n",
    "# compare prediction accuracy \n",
    "correct_pred = tf.equal(tf.argmax(tf.nn.softmax(output),1),tf.argmax(y_labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training and testing</h1>\n",
    "<h2>1.Print out validation accuracy after each training poch</h2>\n",
    "<h2>2.Print out training time you spend on each epoch</h2>\n",
    "<h2>3.Print out testing accuracy in the end</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T01:20:06.221802Z",
     "start_time": "2019-04-27T01:19:14.613203Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Epoch: \t0\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Current Loss is : \t\n",
      "1.5920053\n",
      "Current minibatch accuracy is: \t\n",
      "0.421875\n",
      "Current validation set accuracy is: \t\n",
      "0.3756\n",
      "Training for Epoch: \t1\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t2\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t3\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t4\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t5\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Current Loss is : \t\n",
      "1.3932073\n",
      "Current minibatch accuracy is: \t\n",
      "0.4296875\n",
      "Current validation set accuracy is: \t\n",
      "0.4648\n",
      "Training for Epoch: \t6\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t7\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t8\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t9\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t10\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Current Loss is : \t\n",
      "1.2971952\n",
      "Current minibatch accuracy is: \t\n",
      "0.578125\n",
      "Current validation set accuracy is: \t\n",
      "0.477\n",
      "Training for Epoch: \t11\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t12\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t13\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t14\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t15\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Current Loss is : \t\n",
      "1.2063239\n",
      "Current minibatch accuracy is: \t\n",
      "0.546875\n",
      "Current validation set accuracy is: \t\n",
      "0.4804\n",
      "Training for Epoch: \t16\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t17\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t18\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t19\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t20\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Current Loss is : \t\n",
      "1.3398021\n",
      "Current minibatch accuracy is: \t\n",
      "0.4765625\n",
      "Current validation set accuracy is: \t\n",
      "0.4912\n",
      "Training for Epoch: \t21\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t22\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t23\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t24\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t25\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Current Loss is : \t\n",
      "1.0077593\n",
      "Current minibatch accuracy is: \t\n",
      "0.625\n",
      "Current validation set accuracy is: \t\n",
      "0.4888\n",
      "Training for Epoch: \t26\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t27\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n",
      "Training for Epoch: \t28\n",
      "Training for Batch: \t1\n",
      "Training for Batch: \t2\n",
      "Training for Batch: \t3\n",
      "Training for Batch: \t4\n",
      "Training for Batch: \t5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0e3045145f68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training for Batch: \\t'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cifar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_preprocessed_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mf_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gscratch/stf/dcashon/ee596/spr2019_ee596/hw2/load_cifar.py\u001b[0m in \u001b[0;36mload_preprocessed_training_batch\u001b[0;34m(batch_id, mini_batch_size)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train_processed_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels_onehot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# seems OK. Will run on Google Cloud for later\n",
    "start = time.time()\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_epochs):\n",
    "        print('Training for Epoch: \\t' + str(i))\n",
    "        batch_num = 1\n",
    "        while batch_num < 6:\n",
    "            print('Training for Batch: \\t' + str(batch_num))\n",
    "            training_data = load_cifar.load_preprocessed_training_batch(batch_num, batch_size)\n",
    "            for data, labels in training_data:\n",
    "                f_dict = {x_data: data, y_labels: labels}\n",
    "                sess.run(to_minimize, feed_dict=f_dict)\n",
    "            batch_num += 1\n",
    "        if i % 5 == 0:\n",
    "            print('Current Loss is : \\t')\n",
    "            current_loss = sess.run(cost, feed_dict=f_dict)\n",
    "            print(current_loss)\n",
    "            print('Current minibatch accuracy is: \\t')\n",
    "            current_acc = sess.run(accuracy, feed_dict=f_dict)\n",
    "            print(current_acc)\n",
    "            print('Current validation set accuracy is: \\t')\n",
    "            val_acc = sess.run(accuracy, feed_dict={x_data:val_data, y_labels:val_labels})\n",
    "            print(val_acc)\n",
    "        \n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T01:13:31.565563Z",
     "start_time": "2019-04-27T01:13:31.082966Z"
    }
   },
   "outputs": [],
   "source": [
    "yolo = load_cifar.load_preprocessed_training_batch(1,128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-27T00:38:47.138481Z",
     "start_time": "2019-04-27T00:38:47.105393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8960"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
